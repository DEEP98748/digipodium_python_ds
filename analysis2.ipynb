{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File flipkart_fashion_products_dataset.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m'\u001b[39;49m\u001b[39mflipkart_fashion_products_dataset.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Dipali\\miniconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:760\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[39mif\u001b[39;00m convert_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    758\u001b[0m     convert_axes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 760\u001b[0m json_reader \u001b[39m=\u001b[39m JsonReader(\n\u001b[0;32m    761\u001b[0m     path_or_buf,\n\u001b[0;32m    762\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[0;32m    763\u001b[0m     typ\u001b[39m=\u001b[39;49mtyp,\n\u001b[0;32m    764\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    765\u001b[0m     convert_axes\u001b[39m=\u001b[39;49mconvert_axes,\n\u001b[0;32m    766\u001b[0m     convert_dates\u001b[39m=\u001b[39;49mconvert_dates,\n\u001b[0;32m    767\u001b[0m     keep_default_dates\u001b[39m=\u001b[39;49mkeep_default_dates,\n\u001b[0;32m    768\u001b[0m     precise_float\u001b[39m=\u001b[39;49mprecise_float,\n\u001b[0;32m    769\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[0;32m    770\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    771\u001b[0m     lines\u001b[39m=\u001b[39;49mlines,\n\u001b[0;32m    772\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    773\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    774\u001b[0m     nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    775\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    776\u001b[0m     encoding_errors\u001b[39m=\u001b[39;49mencoding_errors,\n\u001b[0;32m    777\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    778\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    779\u001b[0m )\n\u001b[0;32m    781\u001b[0m \u001b[39mif\u001b[39;00m chunksize:\n\u001b[0;32m    782\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mc:\\Users\\Dipali\\miniconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:861\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    860\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mujson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 861\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_from_filepath(filepath_or_buffer)\n\u001b[0;32m    862\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mc:\\Users\\Dipali\\miniconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py:917\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    909\u001b[0m     filepath_or_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[0;32m    910\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[0;32m    911\u001b[0m     \u001b[39misinstance\u001b[39m(filepath_or_buffer, \u001b[39mstr\u001b[39m)\n\u001b[0;32m    912\u001b[0m     \u001b[39mand\u001b[39;00m filepath_or_buffer\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    916\u001b[0m ):\n\u001b[1;32m--> 917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mfilepath_or_buffer\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    919\u001b[0m \u001b[39mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File flipkart_fashion_products_dataset.json does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('flipkart_fashion_products_dataset.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". load data\n",
    ". look at the data\n",
    ". if required clean the data\n",
    ". if required, transform the data\n",
    ". if required, reduce the data\n",
    ". if required, create new features(new column)\n",
    ". visualize the data\n",
    ". comute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ['actual_price'].str.replace(',','') #remove comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(value):\n",
    "    if not value:\n",
    "        return np.nan\n",
    "    elif isinstance(value, str):\n",
    "        value = value.replace(',','')\n",
    "        if value.isnumeric():\n",
    "            return float(value)\n",
    "    else:    \n",
    "        return value\n",
    "    #print(value)\n",
    "\n",
    "    df['actual_price'].apply(clean_price)#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_price'] = df['actual_price'].apply(clean_price) #actual implementation\n",
    "df['selling_price'] = df['selling_price'].apply(clean_price) #actual implementation\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_discount(value):\n",
    "    if not value:\n",
    "        return np.nan\n",
    "    elif isinstance(value,str):\n",
    "        value=value.replace('% off','')\n",
    "        try:\n",
    "            value=float(value)\n",
    "            return value\n",
    "        except:\n",
    "            print(value)  #to get an idea of what value is failed\n",
    "            return np.nan\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "#test\n",
    "df['discount'].apply(clean_discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discount']=df['discount'].apply(clean_discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rating(value):\n",
    "    if value:\n",
    "        return float(value)\n",
    "    return np.nan\n",
    "\n",
    "#test\n",
    "df['average_rating'].apply(clean_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['out_of_stock'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='selling_price',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['selling_price','title'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_selling_price_df=df.sort_values(by='selling_price',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_selling_price_df.drop_duplicates(subset=['title'], inplace=True) #drop duplicates\n",
    "px.bar(high_selling_price_df.head(25), y='title',\n",
    "       x= 'selling_price', color='out_of_stock', width=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar_polar(high_selling_price_df.head(25), r='selling_price',\n",
    "       theta= 'selling_price', color='out_of_stock', width=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line_polar(high_selling_price_df.head(25), r='selling_price',\n",
    "       theta= 'title', color='out_of_stock', width=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter(high_selling_price_df, y='selling_price',\n",
    "       x= 'actual_price', hover_name='title', trendline='ols')\n",
    "fig.update_traces(marker=dict(size=10,color='red'),\n",
    "                   selector=dict(mode='markers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= px.scatter(high_selling_price_df,y='selling_price',x='actual_price',\n",
    "                hover_name='title', trendline='ols',\n",
    "                animation_frame='brand', animation_group='title')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
